{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 에너지 기반 모델 (energy-based model)\n",
    "\n",
    "mnist dataset으로 실습해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset \n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "(x_train, _), (x_test, _) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 17:01:38.706171: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-16 17:01:38.706315: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs = (imgs.astype('float32') - 127.5) / 127.5\n",
    "    imgs = np.pad(imgs, ((0,0), (2,2), (2,2)), constant_values = -1.0)\n",
    "    imgs = np.expand_dims(imgs, -1)\n",
    "    return imgs\n",
    "\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)\n",
    "x_train = tf.data.Dataset.from_tensor_slices(x_train).batch(128)\n",
    "x_test = tf.data.Dataset.from_tensor_slices(x_test).batch(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook_utils import display, sample_batch\n",
    "\n",
    "sample_train = sample_batch(x_train)\n",
    "display(sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 16)        416       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,993\n",
      "Trainable params: 76,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 에너지 함수 신경망 - swish activation func\n",
    "from tensorflow.keras import (layers,\n",
    "                              models,\n",
    "                              optimizers,\n",
    "                              activations,\n",
    "                              metrics,\n",
    "                              callbacks,\n",
    ")\n",
    "\n",
    "ebm_input = layers.Input(shape=(32, 32, 1))\n",
    "x = layers.Conv2D(\n",
    "    16, kernel_size=5, strides=2, padding=\"same\", activation=activations.swish\n",
    ")(ebm_input)\n",
    "x = layers.Conv2D(\n",
    "    32, kernel_size=3, strides=2, padding=\"same\", activation=activations.swish\n",
    ")(x)\n",
    "x = layers.Conv2D(\n",
    "    64, kernel_size=3, strides=2, padding=\"same\", activation=activations.swish\n",
    ")(x)\n",
    "x = layers.Conv2D(\n",
    "    64, kernel_size=3, strides=2, padding=\"same\", activation=activations.swish\n",
    ")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation=activations.swish)(x)\n",
    "ebm_output = layers.Dense(1)(x)\n",
    "model = models.Model(ebm_input, ebm_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랑주뱅 동역학을 사용하여 샘플을 생성하는 함수\n",
    "\n",
    "def generate_samples(\n",
    "    model, inp_imgs, steps, step_size, noise, return_img_per_step=False\n",
    "):\n",
    "    imgs_per_step = []\n",
    "    for _ in range(steps):\n",
    "        inp_imgs += tf.random.normal(inp_imgs.shape, mean=0, stddev=noise)\n",
    "        inp_imgs = tf.clip_by_value(inp_imgs, -1.0, 1.0)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(inp_imgs)\n",
    "            out_score = model(inp_imgs)\n",
    "        grads = tape.gradient(out_score, inp_imgs)\n",
    "        grads = tf.clip_by_value(grads, -0.03, 0.03)\n",
    "        inp_imgs += step_size * grads\n",
    "        inp_imgs = tf.clip_by_value(inp_imgs, -1.0, 1.0)\n",
    "        if return_img_per_step:\n",
    "            imgs_per_step.append(inp_imgs)\n",
    "    if return_img_per_step:\n",
    "        return tf.stack(imgs_per_step, axis=0)\n",
    "    else:\n",
    "        return inp_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample을 저장할 buffer 클래스\n",
    "import random\n",
    "\n",
    "class Buffer:\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.examples = [\n",
    "            tf.random.uniform(shape=(1, 32, 32, 1)) * 2\n",
    "            - 1\n",
    "            for _ in range(128)\n",
    "        ]\n",
    "\n",
    "    def sample_new_exmps(self, steps, step_size, noise):\n",
    "        n_new = np.random.binomial(128, 0.05)\n",
    "        rand_imgs = (\n",
    "            tf.random.uniform((n_new, 32, 32, 1)) * 2 - 1\n",
    "        )\n",
    "        old_imgs = tf.concat(\n",
    "            random.choices(self.examples, k=128 - n_new), axis=0\n",
    "        )\n",
    "        inp_imgs = tf.concat([rand_imgs, old_imgs], axis=0)\n",
    "        inp_imgs = generate_samples(\n",
    "            self.model, inp_imgs, steps=steps, step_size=step_size, noise=noise\n",
    "        )\n",
    "        self.examples = tf.split(inp_imgs, 128, axis=0) + self.examples\n",
    "        self.examples = self.examples[:8192]\n",
    "        return inp_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBM(models.Model):\n",
    "    def __init__(self):\n",
    "        super(EBM, self).__init__()\n",
    "        self.model = model\n",
    "        self.buffer = Buffer(self.model)\n",
    "        self.alpha = 0.1\n",
    "        self.loss_metric = metrics.Mean(name=\"loss\")\n",
    "        self.reg_loss_metric = metrics.Mean(name=\"reg\")\n",
    "        self.cdiv_loss_metric = metrics.Mean(name=\"cdiv\")\n",
    "        self.real_out_metric = metrics.Mean(name=\"real\")\n",
    "        self.fake_out_metric = metrics.Mean(name=\"fake\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.loss_metric,\n",
    "            self.reg_loss_metric,\n",
    "            self.cdiv_loss_metric,\n",
    "            self.real_out_metric,\n",
    "            self.fake_out_metric,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, real_imgs):\n",
    "        real_imgs += tf.random.normal(\n",
    "            shape=tf.shape(real_imgs), mean=0, stddev=0.005\n",
    "        )\n",
    "        real_imgs = tf.clip_by_value(real_imgs, -1.0, 1.0)\n",
    "        fake_imgs = self.buffer.sample_new_exmps(\n",
    "            steps=60, step_size=10, noise= 0.005\n",
    "        )\n",
    "        inp_imgs = tf.concat([real_imgs, fake_imgs], axis=0)\n",
    "        with tf.GradientTape() as training_tape:\n",
    "            real_out, fake_out = tf.split(self.model(inp_imgs), 2, axis=0)\n",
    "            cdiv_loss = tf.reduce_mean(fake_out, axis=0) - tf.reduce_mean(\n",
    "                real_out, axis=0\n",
    "            )\n",
    "            reg_loss = self.alpha * tf.reduce_mean(\n",
    "                real_out**2 + fake_out**2, axis=0\n",
    "            )\n",
    "            loss = cdiv_loss + reg_loss\n",
    "        grads = training_tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables)\n",
    "        )\n",
    "        self.loss_metric.update_state(loss)\n",
    "        self.reg_loss_metric.update_state(reg_loss)\n",
    "        self.cdiv_loss_metric.update_state(cdiv_loss)\n",
    "        self.real_out_metric.update_state(tf.reduce_mean(real_out, axis=0))\n",
    "        self.fake_out_metric.update_state(tf.reduce_mean(fake_out, axis=0))\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, real_imgs):\n",
    "        batch_size = real_imgs.shape[0]\n",
    "        fake_imgs = (\n",
    "            tf.random.uniform((batch_size, 32, 32, 1))\n",
    "            * 2\n",
    "            - 1\n",
    "        )\n",
    "        inp_imgs = tf.concat([real_imgs, fake_imgs], axis=0)\n",
    "        real_out, fake_out = tf.split(self.model(inp_imgs), 2, axis=0)\n",
    "        cdiv = tf.reduce_mean(fake_out, axis=0) - tf.reduce_mean(\n",
    "            real_out, axis=0\n",
    "        )\n",
    "        self.cdiv_loss_metric.update_state(cdiv)\n",
    "        self.real_out_metric.update_state(tf.reduce_mean(real_out, axis=0))\n",
    "        self.fake_out_metric.update_state(tf.reduce_mean(fake_out, axis=0))\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 27/469 [>.............................] - ETA: 4:28 - loss: 0.0423 - reg: 0.0011 - cdiv: 0.0412 - real: 0.0425 - fake: 0.0837"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pn/6632v8q9641cv_mxbfsbzvc80000gn/T/ipykernel_39172/3965587443.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;31m# train ebm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mebm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 모델 컴파일 및 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;31m# If eval data_handler exists, delete it after all epochs are done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_eval_data_handler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_data_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1036\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         run_step = tf.function(\n\u001b[1;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[1;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n\u001b[1;32m   1043\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0;31m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m       \u001b[0;31m# applied when the caller is also in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2884\u001b[0m     \u001b[0m_require_cross_replica_or_default_context_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pn/6632v8q9641cv_mxbfsbzvc80000gn/T/ipykernel_39172/1510243558.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, real_imgs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         real_imgs += tf.random.normal(\n\u001b[1;32m     25\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         )\n\u001b[1;32m     27\u001b[0m         \u001b[0mreal_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         fake_imgs = self.buffer.sample_new_exmps(\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         )\n\u001b[1;32m     31\u001b[0m         \u001b[0minp_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pn/6632v8q9641cv_mxbfsbzvc80000gn/T/ipykernel_39172/311644687.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, steps, step_size, noise)\u001b[0m\n\u001b[1;32m     19\u001b[0m         old_imgs = tf.concat(\n\u001b[1;32m     20\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m         \u001b[0minp_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         inp_imgs = generate_samples(\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         )\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pn/6632v8q9641cv_mxbfsbzvc80000gn/T/ipykernel_39172/3822548424.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, inp_imgs, steps, step_size, noise, return_img_per_step)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_img_per_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ):\n\u001b[1;32m      6\u001b[0m     \u001b[0mimgs_per_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0minp_imgs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minp_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[1;32m     92\u001b[0m         shape_tensor, dtype, seed=seed1, seed2=seed2)\n\u001b[1;32m     93\u001b[0m     \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstddev_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     new_vals = gen_sparse_ops.sparse_dense_cwise_mul(y.indices, y.values,\n\u001b[1;32m   1763\u001b[0m                                                      y.dense_shape, x, name)\n\u001b[1;32m   1764\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m    \u001b[0;34m*\u001b[0m \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhen\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mincompatible\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m   \"\"\"\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge/envs/aiffel/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6578\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6579\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6580\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6581\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6582\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6583\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6584\u001b[0m       return mul_eager_fallback(\n\u001b[1;32m   6585\u001b[0m           x, y, name=name, ctx=_ctx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train ebm\n",
    "\n",
    "ebm = EBM()\n",
    "# 모델 컴파일 및 훈련\n",
    "ebm.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001), run_eagerly=True\n",
    ")\n",
    "\n",
    "# 이 셀은 오래 걸리므로 에포크 횟수를 10으로 낮추어 실행합니다.\n",
    "ebm.fit(\n",
    "    x_train,\n",
    "    shuffle=True,\n",
    "    epochs=50,  # 50\n",
    "    validation_data=x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
